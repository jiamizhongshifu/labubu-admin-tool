//
//  CameraPreviewView.swift
//  jitata
//
//  Created by é’Ÿåº†æ ‡ on 2025/6/7.
//

import SwiftUI
import AVFoundation
import UIKit

struct CameraPreviewView: UIViewRepresentable {
    @ObservedObject var cameraManager: CameraManager
    var onTap: ((CGPoint) -> Void)?
    
    func makeUIView(context: Context) -> UIView {
        let view = CameraPreviewUIView()
        view.cameraManager = cameraManager
        view.onTap = onTap
        
        if let previewLayer = cameraManager.previewLayer {
            previewLayer.frame = view.bounds
            previewLayer.videoGravity = .resizeAspectFill
            view.layer.addSublayer(previewLayer)
        }
        
        return view
    }
    
    func updateUIView(_ uiView: UIView, context: Context) {
        if let previewLayer = cameraManager.previewLayer {
            previewLayer.frame = uiView.bounds
        }
        
        if let previewView = uiView as? CameraPreviewUIView {
            previewView.onTap = onTap
        }
    }
}

// MARK: - è‡ªå®šä¹‰UIViewæ”¯æŒç‚¹å‡»å¯¹ç„¦
class CameraPreviewUIView: UIView {
    var cameraManager: CameraManager?
    var onTap: ((CGPoint) -> Void)?
    
    override init(frame: CGRect) {
        super.init(frame: frame)
        setupGestureRecognizer()
    }
    
    required init?(coder: NSCoder) {
        super.init(coder: coder)
        setupGestureRecognizer()
    }
    
    private func setupGestureRecognizer() {
        let tapGesture = UITapGestureRecognizer(target: self, action: #selector(handleTap(_:)))
        addGestureRecognizer(tapGesture)
    }
    
    @objc private func handleTap(_ gesture: UITapGestureRecognizer) {
        let location = gesture.location(in: self)
        
        // è°ƒç”¨å¤–éƒ¨ä¼ å…¥çš„ç‚¹å‡»å¤„ç†å‡½æ•°
        onTap?(location)
        
        // åŒæ—¶è°ƒç”¨ç›¸æœºå¯¹ç„¦
        cameraManager?.focusAt(point: location, in: self)
    }
}

// MARK: - ç›¸æœºç®¡ç†å™¨
class CameraManager: NSObject, ObservableObject {
    @Published var capturedImage: UIImage?
    @Published var isSessionRunning = false
    @Published var hasPermission = false
    
    private let session = AVCaptureSession()
    private let photoOutput = AVCapturePhotoOutput()
    private var videoDeviceInput: AVCaptureDeviceInput?
    private var videoDevice: AVCaptureDevice?
    
    var previewLayer: AVCaptureVideoPreviewLayer?
    
    override init() {
        super.init()
        setupCamera()
    }
    
    private func setupCamera() {
        // æ£€æŸ¥ç›¸æœºæƒé™
        checkCameraPermission()
    }
    
    private func checkCameraPermission() {
        switch AVCaptureDevice.authorizationStatus(for: .video) {
        case .authorized:
            hasPermission = true
            configureSession()
        case .notDetermined:
            AVCaptureDevice.requestAccess(for: .video) { granted in
                DispatchQueue.main.async {
                    self.hasPermission = granted
                    if granted {
                        self.configureSession()
                    }
                }
            }
        case .denied, .restricted:
            hasPermission = false
        @unknown default:
            hasPermission = false
        }
    }
    
    private func configureSession() {
        session.beginConfiguration()
        
        // è®¾ç½®ä¼šè¯è´¨é‡
        if session.canSetSessionPreset(.photo) {
            session.sessionPreset = .photo
        }
        
        // æ·»åŠ è§†é¢‘è¾“å…¥
        guard let videoDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
            session.commitConfiguration()
            return
        }
        
        self.videoDevice = videoDevice
        
        do {
            let videoDeviceInput = try AVCaptureDeviceInput(device: videoDevice)
            
            if session.canAddInput(videoDeviceInput) {
                session.addInput(videoDeviceInput)
                self.videoDeviceInput = videoDeviceInput
            }
            
            // é…ç½®è‡ªåŠ¨å¯¹ç„¦
            try videoDevice.lockForConfiguration()
            
            // ğŸ¯ ä¼˜åŒ–å¯¹ç„¦é…ç½®ï¼Œå¢å¼ºè¿‘è·ç¦»å¯¹ç„¦èƒ½åŠ›
            if videoDevice.isFocusModeSupported(.autoFocus) {
                videoDevice.focusMode = .autoFocus  // æ”¹ä¸ºå•æ¬¡è‡ªåŠ¨å¯¹ç„¦ï¼Œæ›´é€‚åˆè¿‘è·ç¦»æ‹æ‘„
            }
            
            // ğŸ¯ å¯ç”¨å¾®è·å¯¹ç„¦ï¼ˆå¦‚æœè®¾å¤‡æ”¯æŒï¼‰
            if #available(iOS 15.0, *) {
                if videoDevice.isAutoFocusRangeRestrictionSupported {
                    videoDevice.autoFocusRangeRestriction = .none  // å…è®¸å…¨èŒƒå›´å¯¹ç„¦ï¼ŒåŒ…æ‹¬å¾®è·
                }
            }
            
            // è®¾ç½®è‡ªåŠ¨æ›å…‰æ¨¡å¼
            if videoDevice.isExposureModeSupported(.continuousAutoExposure) {
                videoDevice.exposureMode = .continuousAutoExposure
            }
            
            // è®¾ç½®è‡ªåŠ¨ç™½å¹³è¡¡
            if videoDevice.isWhiteBalanceModeSupported(.continuousAutoWhiteBalance) {
                videoDevice.whiteBalanceMode = .continuousAutoWhiteBalance
            }
            
            // ğŸ¯ å¯ç”¨å¹³æ»‘è‡ªåŠ¨å¯¹ç„¦ï¼ˆå‡å°‘å¯¹ç„¦æ—¶çš„æŠ–åŠ¨ï¼‰
            if videoDevice.isSmoothAutoFocusSupported {
                videoDevice.isSmoothAutoFocusEnabled = true
            }
            
            videoDevice.unlockForConfiguration()
            
        } catch {
            print("æ— æ³•åˆ›å»ºè§†é¢‘è¾“å…¥æˆ–é…ç½®è®¾å¤‡: \(error)")
            session.commitConfiguration()
            return
        }
        
        // æ·»åŠ ç…§ç‰‡è¾“å‡º
        if session.canAddOutput(photoOutput) {
            session.addOutput(photoOutput)
            
            // ä½¿ç”¨æ–°çš„APIè®¾ç½®æœ€å¤§ç…§ç‰‡å°ºå¯¸
            if #available(iOS 16.0, *) {
                photoOutput.maxPhotoDimensions = CMVideoDimensions(width: 4032, height: 3024)
            } else {
                photoOutput.isHighResolutionCaptureEnabled = true
            }
            
            if let connection = photoOutput.connection(with: .video) {
                if connection.isVideoStabilizationSupported {
                    connection.preferredVideoStabilizationMode = .auto
                }
            }
        }
        
        session.commitConfiguration()
        
        // åˆ›å»ºé¢„è§ˆå±‚
        previewLayer = AVCaptureVideoPreviewLayer(session: session)
        
        // å¯åŠ¨ä¼šè¯
        DispatchQueue.global(qos: .userInitiated).async {
            self.session.startRunning()
            DispatchQueue.main.async {
                self.isSessionRunning = self.session.isRunning
            }
        }
    }
    
    func capturePhoto() {
        guard hasPermission && isSessionRunning else { return }
        
        var settings = AVCapturePhotoSettings()
        
        // è®¾ç½®ç…§ç‰‡æ ¼å¼ - ä½¿ç”¨æ–°çš„API
        if #available(iOS 17.0, *) {
            if photoOutput.availablePhotoCodecTypes.contains(.hevc) {
                settings = AVCapturePhotoSettings(format: [AVVideoCodecKey: AVVideoCodecType.hevc])
            }
        }
        
        // å¯ç”¨é«˜åˆ†è¾¨ç‡ - ä½¿ç”¨æ–°çš„API
        if #available(iOS 16.0, *) {
            settings.maxPhotoDimensions = CMVideoDimensions(width: 4032, height: 3024)
        } else {
            settings.isHighResolutionPhotoEnabled = true
        }
        
        // æ‹ç…§
        photoOutput.capturePhoto(with: settings, delegate: self)
    }
    
    func startSession() {
        guard !isSessionRunning else { return }
        
        DispatchQueue.global(qos: .userInitiated).async {
            self.session.startRunning()
            DispatchQueue.main.async {
                self.isSessionRunning = self.session.isRunning
            }
        }
    }
    
    func stopSession() {
        guard isSessionRunning else { return }
        
        DispatchQueue.global(qos: .userInitiated).async {
            self.session.stopRunning()
            DispatchQueue.main.async {
                self.isSessionRunning = self.session.isRunning
            }
        }
    }
    
    // MARK: - å¯¹ç„¦åŠŸèƒ½
    func focusAt(point: CGPoint, in view: UIView) {
        guard let videoDevice = self.videoDevice,
              let previewLayer = self.previewLayer else { 
            print("âŒ å¯¹ç„¦å¤±è´¥ï¼šè®¾å¤‡æˆ–é¢„è§ˆå±‚ä¸å¯ç”¨")
            return 
        }
        
        print("ğŸ¯ å¼€å§‹æ‰‹åŠ¨å¯¹ç„¦ï¼Œç‚¹å‡»ä½ç½®: (\(point.x), \(point.y))")
        
        // å°†å±å¹•åæ ‡è½¬æ¢ä¸ºç›¸æœºåæ ‡
        let devicePoint = previewLayer.captureDevicePointConverted(fromLayerPoint: point)
        print("ğŸ“ è½¬æ¢åçš„è®¾å¤‡åæ ‡: (\(devicePoint.x), \(devicePoint.y))")
        
        do {
            try videoDevice.lockForConfiguration()
            
            // ğŸ¯ ä¼˜åŒ–å¯¹ç„¦è®¾ç½®ï¼Œç‰¹åˆ«é’ˆå¯¹è¿‘è·ç¦»å¯¹ç„¦
            if videoDevice.isFocusPointOfInterestSupported {
                videoDevice.focusPointOfInterest = devicePoint
                
                // ğŸ¯ ä½¿ç”¨å•æ¬¡è‡ªåŠ¨å¯¹ç„¦ï¼Œæ›´é€‚åˆæ‰‹åŠ¨ç‚¹å‡»å¯¹ç„¦
                if videoDevice.isFocusModeSupported(.autoFocus) {
                    videoDevice.focusMode = .autoFocus
                    print("âœ… è®¾ç½®å•æ¬¡è‡ªåŠ¨å¯¹ç„¦æ¨¡å¼")
                }
                
                // ğŸ¯ å¯ç”¨å¾®è·å¯¹ç„¦èŒƒå›´ï¼ˆå¦‚æœæ”¯æŒï¼‰
                if #available(iOS 15.0, *) {
                    if videoDevice.isAutoFocusRangeRestrictionSupported {
                        videoDevice.autoFocusRangeRestriction = .none
                        print("âœ… å¯ç”¨å…¨èŒƒå›´å¯¹ç„¦ï¼ˆåŒ…æ‹¬å¾®è·ï¼‰")
                    }
                }
            } else {
                print("âš ï¸ è®¾å¤‡ä¸æ”¯æŒå¯¹ç„¦ç‚¹è®¾ç½®")
            }
            
            // è®¾ç½®æ›å…‰ç‚¹
            if videoDevice.isExposurePointOfInterestSupported {
                videoDevice.exposurePointOfInterest = devicePoint
                if videoDevice.isExposureModeSupported(.autoExpose) {
                    videoDevice.exposureMode = .autoExpose
                    print("âœ… è®¾ç½®æ›å…‰ç‚¹")
                }
            }
            
            videoDevice.unlockForConfiguration()
            print("âœ… æ‰‹åŠ¨å¯¹ç„¦è®¾ç½®å®Œæˆ")
            
        } catch {
            print("âŒ å¯¹ç„¦å¤±è´¥: \(error.localizedDescription)")
        }
    }
}

// MARK: - AVCapturePhotoCaptureDelegate
extension CameraManager: AVCapturePhotoCaptureDelegate {
    func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            print("æ‹ç…§é”™è¯¯: \(error)")
            return
        }
        
        guard let imageData = photo.fileDataRepresentation(),
              let image = UIImage(data: imageData) else {
            print("æ— æ³•è·å–å›¾åƒæ•°æ®")
            return
        }
        
        DispatchQueue.main.async {
            self.capturedImage = image
        }
    }
} 