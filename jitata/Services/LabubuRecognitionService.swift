//
//  LabubuRecognitionService.swift
//  jitata
//
//  Created by AI Assistant on 2025/6/7.
//

import Foundation
import UIKit
import SwiftUI
import Vision
import CoreImage

/// çœŸæ­£çš„Labubuè¯†åˆ«æœåŠ¡
/// åŸºäºå›¾åƒç‰¹å¾æå–å’Œæ•°æ®åº“æ¯”å¯¹çš„è¯†åˆ«æ–¹æ¡ˆ
class LabubuRecognitionService: ObservableObject {
    
    static let shared = LabubuRecognitionService()
    
    // MARK: - ä¾èµ–æœåŠ¡
    private let databaseManager = LabubuDatabaseManager.shared
    private let featureExtractor = LabubuFeatureExtractor.shared
    private let similarityMatcher = LabubuSimilarityMatcher.shared
    
    // MARK: - çŠ¶æ€ç®¡ç†
    @Published var isRecognizing = false
    @Published var recognitionProgress: Double = 0.0
    @Published var lastRecognitionResult: LabubuRecognitionResult?
    
    private init() {}
    
    // MARK: - ä¸»è¦è¯†åˆ«æ–¹æ³•
    
    /// è¯†åˆ«Labubuï¼ˆçœŸå®ç‰ˆæœ¬ï¼‰
    /// - Parameter image: ç”¨æˆ·æ‹æ‘„çš„å›¾ç‰‡
    /// - Returns: è¯†åˆ«ç»“æœ
    func recognizeLabubu(_ image: UIImage) async throws -> LabubuRecognitionResult {
        print("ğŸ” å¼€å§‹çœŸå®Labubuè¯†åˆ«...")
        
        await MainActor.run {
            isRecognizing = true
            recognitionProgress = 0.0
        }
        
        defer {
            Task { @MainActor in
                isRecognizing = false
                recognitionProgress = 1.0
            }
        }
        
        let startTime = Date()
        
        do {
            // ç¬¬ä¸€æ­¥ï¼šé¢„å¤„ç†å›¾åƒ (10%)
            await updateProgress(0.1)
            let preprocessedImage = try await preprocessImage(image)
            
            // ç¬¬äºŒæ­¥ï¼šå¿«é€Ÿæ£€æµ‹æ˜¯å¦ä¸ºLabubu (20%)
            await updateProgress(0.2)
            let isLabubu = try await quickLabubuDetection(preprocessedImage)
            
            if !isLabubu {
                throw LabubuRecognitionError.imageProcessingFailed
            }
            
            // ç¬¬ä¸‰æ­¥ï¼šæå–å›¾ç‰‡ç‰¹å¾ (60%)
            await updateProgress(0.6)
            let features = try await extractImageFeatures(preprocessedImage)
            
            // ç¬¬å››æ­¥ï¼šæ•°æ®åº“åŒ¹é… (90%)
            await updateProgress(0.9)
            let matchResults = try await findBestMatches(features: features)
            
            // ç¬¬äº”æ­¥ï¼šæ„å»ºç»“æœ (100%)
            await updateProgress(1.0)
            let result = try await buildRecognitionResult(
                image: image,
                matchResults: matchResults,
                features: features,
                processingTime: Date().timeIntervalSince(startTime)
            )
            
            await MainActor.run {
                lastRecognitionResult = result
            }
            
            print("âœ… è¯†åˆ«å®Œæˆ: \(result.bestMatch?.model.name ?? "æœªè¯†åˆ«")")
            return result
            
        } catch {
            print("âŒ è¯†åˆ«å¤±è´¥: \(error)")
            throw error
        }
    }
    
    // MARK: - è¯†åˆ«æ­¥éª¤å®ç°
    
    /// é¢„å¤„ç†å›¾åƒ
    private func preprocessImage(_ image: UIImage) async throws -> UIImage {
        return try await withCheckedThrowingContinuation { continuation in
            DispatchQueue.global(qos: .userInitiated).async {
                guard let ciImage = CIImage(image: image) else {
                    continuation.resume(throwing: LabubuRecognitionError.imageProcessingFailed)
                    return
                }
                
                let context = CIContext()
                
                // 1. è°ƒæ•´äº®åº¦å’Œå¯¹æ¯”åº¦
                let adjustedImage = ciImage
                    .applyingFilter("CIColorControls", parameters: [
                        "inputBrightness": 0.1,
                        "inputContrast": 1.2,
                        "inputSaturation": 1.1
                    ])
                
                // 2. é™å™ª
                let denoisedImage = adjustedImage
                    .applyingFilter("CINoiseReduction", parameters: [
                        "inputNoiseLevel": 0.02,
                        "inputSharpness": 0.4
                    ])
                
                // 3. è½¬æ¢å›UIImage
                guard let cgImage = context.createCGImage(denoisedImage, from: denoisedImage.extent) else {
                    continuation.resume(throwing: LabubuRecognitionError.imageProcessingFailed)
                    return
                }
                
                let processedImage = UIImage(cgImage: cgImage)
                continuation.resume(returning: processedImage)
            }
        }
    }
    
    /// å¿«é€Ÿæ£€æµ‹æ˜¯å¦ä¸ºLabubu
    private func quickLabubuDetection(_ image: UIImage) async throws -> Bool {
        // ä½¿ç”¨Visionæ¡†æ¶è¿›è¡Œç‰©ä½“æ£€æµ‹
        return try await withCheckedThrowingContinuation { continuation in
            guard let cgImage = image.cgImage else {
                continuation.resume(throwing: LabubuRecognitionError.imageProcessingFailed)
                return
            }
            
            // åˆ›å»ºç‰©ä½“æ£€æµ‹è¯·æ±‚
            let request = VNDetectRectanglesRequest { request, error in
                if let error = error {
                    continuation.resume(throwing: error)
                    return
                }
                
                // æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°çŸ©å½¢ç‰©ä½“ï¼ˆLabubuçš„åŸºæœ¬å½¢çŠ¶ï¼‰
                let hasRectangularObject = request.results?.isEmpty == false
                
                // ç®€åŒ–ç‰ˆæœ¬ï¼šå¦‚æœæ£€æµ‹åˆ°ç‰©ä½“ï¼Œå‡è®¾æ˜¯Labubu
                // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„åˆ†ç±»å™¨
                continuation.resume(returning: hasRectangularObject)
            }
            
            request.minimumAspectRatio = 0.3
            request.maximumAspectRatio = 2.0
            request.minimumSize = 0.1
            request.maximumObservations = 10
            
            let handler = VNImageRequestHandler(cgImage: cgImage)
            
            do {
                try handler.perform([request])
            } catch {
                continuation.resume(throwing: error)
            }
        }
    }
    
    /// æå–å›¾ç‰‡ç‰¹å¾
    private func extractImageFeatures(_ image: UIImage) async throws -> VisualFeatures {
        return try await featureExtractor.extractFeatures(from: image)
    }
    
    /// åœ¨æ•°æ®åº“ä¸­æŸ¥æ‰¾æœ€ä½³åŒ¹é…
    private func findBestMatches(features: VisualFeatures) async throws -> [MatchResult] {
        let allModels = databaseManager.getAllModels()
        
        guard !allModels.isEmpty else {
            throw LabubuRecognitionError.serviceUnavailable
        }
        
        // ä½¿ç”¨ç›¸ä¼¼åº¦åŒ¹é…å™¨è¿›è¡ŒåŒ¹é…
        let matches = try await similarityMatcher.findSimilarModels(
            userFeatures: features,
            candidateModels: allModels,
            maxResults: 5
        )
        
        return matches
    }
    
    /// æ„å»ºè¯†åˆ«ç»“æœ
    private func buildRecognitionResult(
        image: UIImage,
        matchResults: [MatchResult],
        features: VisualFeatures,
        processingTime: TimeInterval
    ) async throws -> LabubuRecognitionResult {
        
        guard let bestMatch = matchResults.first else {
            return LabubuRecognitionResult(
                originalImage: image,
                bestMatch: nil,
                alternatives: [],
                confidence: 0.0,
                processingTime: processingTime,
                features: features,
                timestamp: Date()
            )
        }
        
        // è·å–ç³»åˆ—ä¿¡æ¯
        let series = databaseManager.getSeries(id: bestMatch.model.seriesId)
        
        // æ„å»ºæœ€ä½³åŒ¹é…
        let labubuMatch = LabubuMatch(
            model: bestMatch.model,
            series: series,
            confidence: bestMatch.confidence,
            matchedFeatures: bestMatch.matchedFeatures.map { $0.featureType.rawValue }
        )
        
        // æ„å»ºå¤‡é€‰é¡¹
        let alternatives = Array(matchResults.dropFirst().prefix(3)).map { $0.model }
        
        return LabubuRecognitionResult(
            originalImage: image,
            bestMatch: labubuMatch,
            alternatives: alternatives,
            confidence: bestMatch.confidence,
            processingTime: processingTime,
            features: features,
            timestamp: Date()
        )
    }
    
    // MARK: - è¾…åŠ©æ–¹æ³•
    
    @MainActor
    private func updateProgress(_ progress: Double) {
        recognitionProgress = progress
    }
}

 