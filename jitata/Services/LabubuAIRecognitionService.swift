//
//  LabubuAIRecognitionService.swift
//  jitata
//
//  Created by AI Assistant on 2025/6/7.
//

import Foundation
import UIKit
import SwiftUI

/// Labubu AIè¯†åˆ«æœåŠ¡ - æ–¹æ¡ˆ3: å¤šæ¨¡æ€AIè¯†åˆ«
/// ä½¿ç”¨TUZI APIè¿›è¡Œå›¾åƒåˆ†æå’Œç‰¹å¾æ–‡æ¡ˆç”Ÿæˆï¼Œç”¨äºæ›¿æ¢ç”¨æˆ·æ‹ç…§åçš„è‡ªåŠ¨è¯†åˆ«ç¯èŠ‚
@MainActor
class LabubuAIRecognitionService: ObservableObject {
    
    static let shared = LabubuAIRecognitionService()
    
    // MARK: - å‘å¸ƒçš„å±æ€§
    @Published var isRecognizing = false
    @Published var recognitionProgress: Double = 0.0
    @Published var recognitionStatus = "å‡†å¤‡è¯†åˆ«"
    @Published var lastRecognitionResult: LabubuAIRecognitionResult?
    @Published var errorMessage: String?
    
    // MARK: - é…ç½®
    private let apiTimeout: TimeInterval = 180.0  // 3åˆ†é’Ÿè¶…æ—¶ï¼Œç¡®ä¿AIæœ‰è¶³å¤Ÿå¤„ç†æ—¶é—´
    private let maxImageSize: CGFloat = 1024      // æé«˜å›¾åƒå°ºå¯¸ï¼Œä¿è¯è¯†åˆ«ç²¾åº¦
    private let compressionQuality: CGFloat = 0.8  // æé«˜å‹ç¼©è´¨é‡ï¼Œä¿è¯å›¾åƒç»†èŠ‚
    private let maxRetryAttempts = 3              // æœ€å¤§é‡è¯•æ¬¡æ•°
    private let retryDelay: TimeInterval = 2.0    // é‡è¯•å»¶è¿Ÿ
    
    // MARK: - æ•°æ®åº“æœåŠ¡
    private let databaseService = LabubuSupabaseDatabaseService.shared
    
    private init() {}
    
    // MARK: - ä¸»è¦è¯†åˆ«æ¥å£
    
    /// è¯†åˆ«ç”¨æˆ·æ‹æ‘„çš„Labubuå›¾ç‰‡
    /// - Parameter image: ç”¨æˆ·æ‹æ‘„çš„å›¾ç‰‡
    /// - Returns: AIè¯†åˆ«ç»“æœ
    func recognizeUserPhoto(_ image: UIImage) async throws -> LabubuAIRecognitionResult {
        print("ğŸ¤– å¼€å§‹AIè¯†åˆ«ç”¨æˆ·æ‹æ‘„çš„Labubu...")
        
        isRecognizing = true
        recognitionProgress = 0.0
        recognitionStatus = "å‡†å¤‡è¯†åˆ«"
        errorMessage = nil
        
        defer {
            isRecognizing = false
        }
        
        do {
            // ç¬¬ä¸€æ­¥ï¼šé¢„å¤„ç†å›¾åƒ (20%)
            recognitionStatus = "é¢„å¤„ç†å›¾åƒ..."
            recognitionProgress = 0.2
            let processedImage = try await preprocessImage(image)
            
            // ç¬¬äºŒæ­¥ï¼šè°ƒç”¨AIåˆ†æ (70%)
            recognitionStatus = "AIåˆ†æä¸­..."
            recognitionProgress = 0.7
            let aiAnalysis = try await callTuziVisionAPI(processedImage)
            
            // ç¬¬ä¸‰æ­¥ï¼šæ•°æ®åº“åŒ¹é… (90%)
            recognitionStatus = "æ•°æ®åº“åŒ¹é…..."
            recognitionProgress = 0.9
            let matchResults = try await matchWithDatabase(aiAnalysis)
            
            // ç¬¬å››æ­¥ï¼šæ„å»ºç»“æœ (100%)
            recognitionStatus = "è¯†åˆ«å®Œæˆ"
            recognitionProgress = 1.0
            
            let result = LabubuAIRecognitionResult(
                originalImage: image,
                aiAnalysis: aiAnalysis,
                matchResults: matchResults,
                processingTime: Date().timeIntervalSince(Date()),
                timestamp: Date()
            )
            
            lastRecognitionResult = result
            
            print("âœ… AIè¯†åˆ«å®Œæˆ: \(result.bestMatch?.name ?? "æœªè¯†åˆ«")")
            return result
            
        } catch {
            print("âŒ AIè¯†åˆ«å¤±è´¥: \(error)")
            errorMessage = error.localizedDescription
            recognitionStatus = "è¯†åˆ«å¤±è´¥"
            throw error
        }
    }
    
    // MARK: - ç§æœ‰æ–¹æ³•
    
    /// é¢„å¤„ç†å›¾åƒ
    private func preprocessImage(_ image: UIImage) async throws -> UIImage {
        return try await withCheckedThrowingContinuation { continuation in
            DispatchQueue.main.async {
                // è°ƒæ•´å›¾åƒå°ºå¯¸ï¼ˆéœ€è¦åœ¨ä¸»çº¿ç¨‹æ‰§è¡Œï¼‰
                let resizedImage = self.resizeImage(image, maxSize: self.maxImageSize)
                
                DispatchQueue.global(qos: .userInitiated).async {
                // å‹ç¼©å›¾åƒ
                guard let compressedData = resizedImage.jpegData(compressionQuality: self.compressionQuality),
                      let finalImage = UIImage(data: compressedData) else {
                    continuation.resume(throwing: LabubuAIError.imageProcessingFailed)
                    return
                }
                
                continuation.resume(returning: finalImage)
                }
            }
        }
    }
    
    /// è°ƒæ•´å›¾åƒå°ºå¯¸
    private func resizeImage(_ image: UIImage, maxSize: CGFloat) -> UIImage {
        let size = image.size
        let ratio = min(maxSize / size.width, maxSize / size.height)
        
        if ratio >= 1.0 {
            return image
        }
        
        let newSize = CGSize(width: size.width * ratio, height: size.height * ratio)
        
        UIGraphicsBeginImageContextWithOptions(newSize, false, 0.0)
        image.draw(in: CGRect(origin: .zero, size: newSize))
        let resizedImage = UIGraphicsGetImageFromCurrentImageContext()
        UIGraphicsEndImageContext()
        
        return resizedImage ?? image
    }
    
    /// è°ƒç”¨TUZI Vision APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
    private func callTuziVisionAPI(_ image: UIImage) async throws -> LabubuAIAnalysis {
        print("ğŸ“ LabubuAIä» \(Bundle.main.bundlePath)/.env è¯»å–åˆ°TUZI_API_KEY")
        print("ğŸ“ LabubuAIä» \(Bundle.main.bundlePath)/.env è¯»å–åˆ°TUZI_API_BASE")
        
        // è·å–APIé…ç½®
        guard let apiKey = getAPIKey(),
              let baseURL = getAPIBaseURL() else {
            print("âŒ APIé…ç½®ç¼ºå¤±")
            throw LabubuAIError.apiConfigurationMissing
        }
        
        print("ğŸ”‘ APIå¯†é’¥å·²è·å–: \(apiKey.prefix(10))...")
        print("ğŸŒ APIåŸºç¡€URL: \(baseURL)")
        
        // è½¬æ¢å›¾åƒä¸ºbase64
        guard let imageData = image.jpegData(compressionQuality: compressionQuality) else {
            print("âŒ å›¾åƒå‹ç¼©å¤±è´¥")
            throw LabubuAIError.imageProcessingFailed
        }
        
        print("ğŸ“· å›¾åƒæ•°æ®å¤§å°: \(imageData.count) å­—èŠ‚")
        print("ğŸ“· å‹ç¼©è´¨é‡: \(compressionQuality)")
        
        let base64Image = "data:image/jpeg;base64," + imageData.base64EncodedString()
        print("ğŸ“ Base64ç¼–ç å®Œæˆï¼Œé•¿åº¦: \(base64Image.count) å­—ç¬¦")
        
        // å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨
        var lastError: Error?
        
        for attempt in 1...maxRetryAttempts {
            print("ğŸ”„ ç¬¬\(attempt)æ¬¡å°è¯•APIè°ƒç”¨...")
            
            do {
                let result = try await performSingleAPICall(apiKey: apiKey, baseURL: baseURL, base64Image: base64Image)
                print("âœ… ç¬¬\(attempt)æ¬¡å°è¯•æˆåŠŸ")
                return result
            } catch {
                lastError = error
                print("âŒ ç¬¬\(attempt)æ¬¡å°è¯•å¤±è´¥: \(error)")
                
                // å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
                if attempt < maxRetryAttempts {
                    print("â³ ç­‰å¾…\(retryDelay)ç§’åé‡è¯•...")
                    try await Task.sleep(nanoseconds: UInt64(retryDelay * 1_000_000_000))
                }
            }
        }
        
        // æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        print("âŒ æ‰€æœ‰\(maxRetryAttempts)æ¬¡å°è¯•éƒ½å¤±è´¥")
        throw lastError ?? LabubuAIError.networkError("APIè°ƒç”¨å¤±è´¥")
    }
    
    /// æ‰§è¡Œå•æ¬¡APIè°ƒç”¨
    private func performSingleAPICall(apiKey: String, baseURL: String, base64Image: String) async throws -> LabubuAIAnalysis {
        // æ„å»ºè¯·æ±‚
        let url = URL(string: "\(baseURL)/chat/completions")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        request.timeoutInterval = apiTimeout
        
        print("ğŸŒ è¯·æ±‚URL: \(url.absoluteString)")
        print("â±ï¸ è¶…æ—¶è®¾ç½®: \(apiTimeout) ç§’")
        
        let requestBody = [
            "model": "gemini-2.5-flash-all",
            "stream": false,  // æ˜ç¡®ç¦ç”¨æµå¼æ¨¡å¼ï¼Œç¡®ä¿å®Œæ•´å“åº”
            "temperature": 0.1,  // é™ä½éšæœºæ€§ï¼Œæé«˜ä¸€è‡´æ€§
            "max_tokens": 2000,  // ç¡®ä¿æœ‰è¶³å¤Ÿçš„tokenè¿”å›å®Œæ•´åˆ†æ
            "messages": [
                [
                    "role": "user",
                    "content": [
                        [
                            "type": "text",
                            "text": buildLabubuRecognitionPrompt()
                        ],
                        [
                            "type": "image_url",
                            "image_url": [
                                "url": base64Image
                            ]
                        ]
                    ]
                ]
            ]
        ] as [String: Any]
        
        do {
            request.httpBody = try JSONSerialization.data(withJSONObject: requestBody)
            print("ğŸ“¦ è¯·æ±‚ä½“å¤§å°: \(request.httpBody?.count ?? 0) å­—èŠ‚")
        } catch {
            print("âŒ è¯·æ±‚ä½“åºåˆ—åŒ–å¤±è´¥: \(error)")
            throw LabubuAIError.jsonParsingFailed
        }
        
        print("ğŸš€ å‘é€APIè¯·æ±‚...")
        
        // å‘é€è¯·æ±‚
            let (data, response) = try await URLSession.shared.data(for: request)
            
            print("ğŸ“¥ æ”¶åˆ°å“åº”ï¼Œæ•°æ®å¤§å°: \(data.count) å­—èŠ‚")
            
            // æ£€æŸ¥å“åº”
            guard let httpResponse = response as? HTTPURLResponse else {
                print("âŒ æ— æ•ˆçš„HTTPå“åº”ç±»å‹")
                throw LabubuAIError.networkError("æ— æ•ˆçš„å“åº”")
            }
            
            print("ğŸ“Š HTTPçŠ¶æ€ç : \(httpResponse.statusCode)")
            
            if httpResponse.statusCode != 200 {
                let errorBody = String(data: data, encoding: .utf8) ?? "æ— æ³•è§£æé”™è¯¯ä¿¡æ¯"
                print("âŒ APIè¯·æ±‚å¤±è´¥: \(httpResponse.statusCode)")
                print("âŒ é”™è¯¯è¯¦æƒ…: \(errorBody)")
            
            // æ ¹æ®HTTPçŠ¶æ€ç æä¾›æ›´å…·ä½“çš„é”™è¯¯ä¿¡æ¯
            switch httpResponse.statusCode {
            case 401:
                throw LabubuAIError.apiConfigurationMissing
            case 429:
                throw LabubuAIError.apiRateLimited
            case 402, 403:
                throw LabubuAIError.apiQuotaExceeded
            case 408, 504:
                throw LabubuAIError.apiTimeout
            case 500...599:
                throw LabubuAIError.invalidResponse
            default:
                throw LabubuAIError.networkError("APIè¯·æ±‚å¤±è´¥: \(httpResponse.statusCode) - \(errorBody)")
            }
            }
            
            // è§£æå“åº”
            do {
                let jsonResponse = try JSONSerialization.jsonObject(with: data) as? [String: Any]
                print("âœ… JSONå“åº”è§£ææˆåŠŸ")
                
                guard let choices = jsonResponse?["choices"] as? [[String: Any]],
                      let firstChoice = choices.first,
                      let message = firstChoice["message"] as? [String: Any],
                      let content = message["content"] as? String else {
                    print("âŒ å“åº”æ ¼å¼æ— æ•ˆ")
                    print("ğŸ“ å“åº”å†…å®¹: \(String(data: data, encoding: .utf8) ?? "æ— æ³•è§£æ")")
                    throw LabubuAIError.invalidResponse
                }
                
                print("ğŸ“ AIåˆ†æå†…å®¹é•¿åº¦: \(content.count) å­—ç¬¦")
                print("ğŸ“ AIåˆ†æå†…å®¹é¢„è§ˆ: \(content.prefix(200))...")
            print("ğŸ“ AIåˆ†æå®Œæ•´å†…å®¹: \(content)")
                
                // è§£æAIåˆ†æç»“æœ
                let result = try parseAIAnalysisResult(content)
                print("âœ… AIåˆ†æç»“æœè§£æå®Œæˆ")
                print("ğŸ¯ è¯†åˆ«ç»“æœ: isLabubu=\(result.isLabubu), confidence=\(result.confidence)")
            print("ğŸ“„ è¯¦ç»†æè¿°: \(result.detailedDescription.prefix(100))...")
                
                return result
                
            } catch {
                print("âŒ JSONè§£æå¤±è´¥: \(error)")
                print("ğŸ“ åŸå§‹å“åº”: \(String(data: data, encoding: .utf8) ?? "æ— æ³•è§£æ")")
                throw LabubuAIError.jsonParsingFailed
        }
    }
    
    /// æ„å»ºLabubuè¯†åˆ«æç¤ºè¯
    private func buildLabubuRecognitionPrompt() -> String {
        return """
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Labubuç©å…·è¯†åˆ«ä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æè¿™å¼ ç”¨æˆ·æ‹æ‘„çš„å›¾ç‰‡ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºLabubuç©å…·ï¼Œå¹¶æä¾›è¯¦ç»†çš„ç‰¹å¾æè¿°ã€‚

        Labubuæ˜¯ä¸€ä¸ªçŸ¥åçš„æ½®ç©å“ç‰Œï¼Œé€šå¸¸å…·æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š
        - å¯çˆ±çš„å¡é€šå½¢è±¡ï¼Œé€šå¸¸æœ‰å¤§çœ¼ç›
        - å¤šç§é¢œè‰²å’Œä¸»é¢˜ç³»åˆ—
        - å¸¸è§æè´¨åŒ…æ‹¬æ¯›ç»’ã€å¡‘æ–™ã€æªèƒ¶ç­‰
        - å°ºå¯¸ä»å°å‹åˆ°å¤§å‹ä¸ç­‰
        - ç»å¸¸æœ‰ç‰¹æ®Šçš„æœè£…ã€é…é¥°æˆ–ä¸»é¢˜è£…æ‰®

        è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼Œç¡®ä¿JSONæ ¼å¼å®Œå…¨æ­£ç¡®ï¼š

        ```json
        {
            "isLabubu": true,
            "confidence": 0.85,
            "detailedDescription": "è¯¦ç»†çš„ç‰¹å¾æè¿°æ–‡æ¡ˆï¼ŒåŒ…æ‹¬é¢œè‰²ã€å½¢çŠ¶ã€æè´¨ã€å›¾æ¡ˆã€é£æ ¼ã€æœè£…ã€é…é¥°ç­‰æ‰€æœ‰å¯è§ç‰¹å¾ï¼Œè¿™æ®µæ–‡æ¡ˆå°†ç”¨äºä¸æ•°æ®åº“ä¸­çš„Labubuæ¨¡å‹è¿›è¡Œæ™ºèƒ½åŒ¹é…ã€‚è¯·å°½å¯èƒ½è¯¦ç»†æè¿°ï¼ŒåŒ…æ‹¬å…·ä½“çš„é¢œè‰²åç§°ã€æè´¨è´¨æ„Ÿã€å›¾æ¡ˆç»†èŠ‚ã€æ•´ä½“é£æ ¼ç­‰",
            "visualFeatures": {
                "dominantColors": ["#FF6B6B", "#4ECDC4", "#45B7D1"],
                "bodyShape": "åœ†æ¶¦",
                "headShape": "åœ†å½¢",
                "earType": "å°–è€³",
                "surfaceTexture": "ç»’æ¯›",
                "patternType": "çº¯è‰²",
                "estimatedSize": "ä¸­å‹"
            },
            "keyFeatures": [
                "å…·ä½“ç‰¹å¾1ï¼ˆå¦‚ï¼šè“è‰²æ¸”å¤«å¸½ï¼‰",
                "å…·ä½“ç‰¹å¾2ï¼ˆå¦‚ï¼šç™½è‰²æ¯›ç»’èº«ä½“ï¼‰", 
                "å…·ä½“ç‰¹å¾3ï¼ˆå¦‚ï¼šå¤§çœ¼ç›è¡¨æƒ…ï¼‰"
            ],
            "seriesHints": "å¯èƒ½çš„ç³»åˆ—åç§°æˆ–ä¸»é¢˜æç¤ºï¼ˆå¦‚ï¼šFall in Wildã€The Monstersç­‰ï¼‰",
            "materialAnalysis": "æè´¨åˆ†æï¼ˆå¦‚ï¼šæ¯›ç»’è´¨åœ°ã€å¡‘æ–™é…ä»¶ã€é‡‘å±è£…é¥°ç­‰ï¼‰",
            "styleAnalysis": "é£æ ¼åˆ†æï¼ˆå¦‚ï¼šæˆ·å¤–æ¢é™©é£æ ¼ã€å¯çˆ±èŒç³»ã€é…·ç‚«è¡—å¤´ç­‰ï¼‰",
            "conditionAssessment": "çŠ¶æ€è¯„ä¼°ï¼ˆå¦‚ï¼šå…¨æ–°ã€è‰¯å¥½ã€è½»å¾®ç£¨æŸç­‰ï¼‰",
            "rarityHints": "ç¨€æœ‰åº¦æç¤ºï¼ˆå¦‚ï¼šå¸¸è§æ¬¾ã€ç¨€æœ‰æ¬¾ã€é™å®šæ¬¾ã€éšè—æ¬¾ç­‰ï¼‰"
        }
        ```

        é‡è¦è¯´æ˜ï¼š
        1. å¦‚æœå›¾ç‰‡ä¸­ä¸æ˜¯Labubuç©å…·ï¼Œè¯·å°†isLabubuè®¾ä¸ºfalseï¼Œconfidenceè®¾ä¸º0.0-0.3
        2. å¦‚æœå›¾ç‰‡ä¸­æ˜¯Labubuç©å…·ï¼Œè¯·å°†isLabubuè®¾ä¸ºtrueï¼Œconfidenceè®¾ä¸º0.6-0.95ä¹‹é—´çš„æ•°å€¼
        3. confidenceå­—æ®µå¿…é¡»æ˜¯æ•°å­—ï¼Œä¸èƒ½æ˜¯å­—ç¬¦ä¸²ï¼ŒèŒƒå›´0.0-1.0
        4. detailedDescriptionå­—æ®µéå¸¸é‡è¦ï¼Œè¯·æä¾›ä¸°å¯Œè¯¦ç»†çš„ç‰¹å¾æè¿°ï¼ŒåŒ…å«æ‰€æœ‰å¯è§çš„ç»†èŠ‚
        5. keyFeaturesè¦å…·ä½“æ˜ç¡®ï¼Œé¿å…æ¨¡ç³Šæè¿°
        6. è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä½¿ç”¨```json```åŒ…å›´
        7. å³ä½¿ä¸ç¡®å®šæ˜¯å¦ä¸ºLabubuï¼Œä¹Ÿè¦å°½å¯èƒ½è¯¦ç»†æè¿°å›¾ç‰‡ä¸­ç©å…·çš„ç‰¹å¾
        """
    }
    
    /// è§£æAIåˆ†æç»“æœï¼ˆå¢å¼ºç‰ˆï¼‰
    private func parseAIAnalysisResult(_ content: String) throws -> LabubuAIAnalysis {
        print("ğŸ” å¼€å§‹è§£æAIåˆ†æç»“æœ...")
        
        // å¤šç§æ–¹å¼æå–JSONå†…å®¹
        let jsonText: String
        
        // æ–¹å¼1: æå–```json```å—
        if let jsonMatch = content.range(of: "```json\\s*([\\s\\S]*?)\\s*```", options: .regularExpression) {
            let fullMatch = String(content[jsonMatch])
            jsonText = fullMatch
                .replacingOccurrences(of: "```json", with: "")
                .replacingOccurrences(of: "```", with: "")
                .trimmingCharacters(in: .whitespacesAndNewlines)
            print("ğŸ“‹ ä»```json```å—ä¸­æå–JSON")
        }
        // æ–¹å¼2: æå–æ™®é€š```ä»£ç å—
        else if let codeMatch = content.range(of: "```\\s*([\\s\\S]*?)\\s*```", options: .regularExpression) {
            let fullMatch = String(content[codeMatch])
            jsonText = fullMatch
                .replacingOccurrences(of: "```", with: "")
                .trimmingCharacters(in: .whitespacesAndNewlines)
            print("ğŸ“‹ ä»```ä»£ç å—ä¸­æå–JSON")
        }
        // æ–¹å¼3: æŸ¥æ‰¾{...}JSONå¯¹è±¡
        else if let jsonStart = content.firstIndex(of: "{"),
                let jsonEnd = content.lastIndex(of: "}") {
            jsonText = String(content[jsonStart...jsonEnd])
            print("ğŸ“‹ ä»{}å¯¹è±¡ä¸­æå–JSON")
        }
        // æ–¹å¼4: ç›´æ¥ä½¿ç”¨åŸå§‹å†…å®¹
        else {
            jsonText = content.trimmingCharacters(in: .whitespacesAndNewlines)
            print("ğŸ“‹ ç›´æ¥ä½¿ç”¨åŸå§‹å†…å®¹ä½œä¸ºJSON")
        }
        
        print("ğŸ“ æå–çš„JSONæ–‡æœ¬: \(jsonText)")
        
        // å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
        let cleanedJsonText = cleanupJsonText(jsonText)
        print("ğŸ§¹ æ¸…ç†åçš„JSONæ–‡æœ¬: \(cleanedJsonText)")
        
        // è§£æJSON
        guard let data = cleanedJsonText.data(using: .utf8) else {
            print("âŒ JSONæ–‡æœ¬è½¬æ¢ä¸ºDataå¤±è´¥")
            throw LabubuAIError.jsonParsingFailed
        }
        
        do {
            guard let json = try JSONSerialization.jsonObject(with: data) as? [String: Any] else {
                print("âŒ JSONååºåˆ—åŒ–å¤±è´¥ - ä¸æ˜¯å­—å…¸ç±»å‹")
                throw LabubuAIError.jsonParsingFailed
            }
            
            print("âœ… JSONè§£ææˆåŠŸï¼Œå­—æ®µ: \(json.keys.sorted())")
            
            // æ„å»ºåˆ†æç»“æœï¼ˆå¢å¼ºå®¹é”™æ€§ï¼‰
        let isLabubu = json["isLabubu"] as? Bool ?? false
            
            // å¤„ç†confidenceå­—æ®µçš„å¤šç§ç±»å‹
            let confidence: Double
            if let confDouble = json["confidence"] as? Double {
                confidence = max(0.0, min(1.0, confDouble))  // ç¡®ä¿åœ¨0-1èŒƒå›´å†…
            } else if let confString = json["confidence"] as? String,
                      let confValue = Double(confString) {
                confidence = max(0.0, min(1.0, confValue))
            } else {
                confidence = isLabubu ? 0.5 : 0.0  // é»˜è®¤å€¼
            }
            
        let detailedDescription = json["detailedDescription"] as? String ?? ""
        let keyFeatures = json["keyFeatures"] as? [String] ?? []
        let seriesHints = json["seriesHints"] as? String ?? ""
        let materialAnalysis = json["materialAnalysis"] as? String ?? ""
        let styleAnalysis = json["styleAnalysis"] as? String ?? ""
        let conditionAssessment = json["conditionAssessment"] as? String ?? ""
        let rarityHints = json["rarityHints"] as? String ?? ""
        
            print("ğŸ” è§£æå­—æ®µå€¼:")
            print("  - isLabubu: \(isLabubu)")
            print("  - confidence: \(confidence)")
            print("  - detailedDescriptioné•¿åº¦: \(detailedDescription.count)")
            print("  - keyFeaturesæ•°é‡: \(keyFeatures.count)")
            
            // è§£æè§†è§‰ç‰¹å¾ï¼ˆå¢å¼ºå®¹é”™æ€§ï¼‰
        var visualFeatures: LabubuVisualFeatures?
        if let featuresDict = json["visualFeatures"] as? [String: Any] {
            visualFeatures = LabubuVisualFeatures(
                dominantColors: featuresDict["dominantColors"] as? [String] ?? [],
                bodyShape: featuresDict["bodyShape"] as? String ?? "",
                headShape: featuresDict["headShape"] as? String ?? "",
                earType: featuresDict["earType"] as? String ?? "",
                surfaceTexture: featuresDict["surfaceTexture"] as? String ?? "",
                patternType: featuresDict["patternType"] as? String ?? "",
                estimatedSize: featuresDict["estimatedSize"] as? String ?? ""
            )
                print("âœ… è§†è§‰ç‰¹å¾è§£ææˆåŠŸ")
            } else {
                print("âš ï¸ æœªæ‰¾åˆ°visualFeatureså­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼")
                visualFeatures = LabubuVisualFeatures(
                    dominantColors: [],
                    bodyShape: "",
                    headShape: "",
                    earType: "",
                    surfaceTexture: "",
                    patternType: "",
                    estimatedSize: ""
                )
        }
        
        return LabubuAIAnalysis(
            isLabubu: isLabubu,
            confidence: confidence,
            detailedDescription: detailedDescription,
            visualFeatures: visualFeatures,
            keyFeatures: keyFeatures,
            seriesHints: seriesHints,
            materialAnalysis: materialAnalysis,
            styleAnalysis: styleAnalysis,
            conditionAssessment: conditionAssessment,
            rarityHints: rarityHints
            )
            
        } catch {
            print("âŒ JSONè§£æå¤±è´¥: \(error)")
            print("ğŸ“ åŸå§‹å†…å®¹: \(content)")
            print("ğŸ“ æ¸…ç†åå†…å®¹: \(cleanedJsonText)")
            
            // å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–åŸºæœ¬ä¿¡æ¯
            return extractBasicInfoFromText(content)
        }
    }
    
    /// æ¸…ç†JSONæ–‡æœ¬ï¼Œä¿®å¤å¸¸è§æ ¼å¼é—®é¢˜
    private func cleanupJsonText(_ text: String) -> String {
        var cleaned = text
        
        // ç§»é™¤å¤šä½™çš„æ¢è¡Œå’Œç©ºæ ¼
        cleaned = cleaned.trimmingCharacters(in: .whitespacesAndNewlines)
        
        // ä¿®å¤å¸¸è§çš„å¼•å·é—®é¢˜ï¼ˆå¢å¼ºç‰ˆï¼‰
        cleaned = cleaned.replacingOccurrences(of: "\u{201C}", with: "\"") // å·¦åŒå¼•å·
        cleaned = cleaned.replacingOccurrences(of: "\u{201D}", with: "\"") // å³åŒå¼•å·
        cleaned = cleaned.replacingOccurrences(of: "\u{2018}", with: "\"") // å·¦å•å¼•å·
        cleaned = cleaned.replacingOccurrences(of: "\u{2019}", with: "\"") // å³å•å¼•å·
        cleaned = cleaned.replacingOccurrences(of: "\u{FF02}", with: "\"") // å…¨è§’åŒå¼•å·
        cleaned = cleaned.replacingOccurrences(of: "\u{FF07}", with: "\"") // å…¨è§’å•å¼•å·
        
        // ä¿®å¤å¸ƒå°”å€¼
        cleaned = cleaned.replacingOccurrences(of: ": true", with: ": true")
        cleaned = cleaned.replacingOccurrences(of: ": false", with: ": false")
        
        // ä¿®å¤æ•°å­—æ ¼å¼é—®é¢˜
        cleaned = cleaned.replacingOccurrences(of: ": 0.", with: ": 0.")
        cleaned = cleaned.replacingOccurrences(of: ": 1.", with: ": 1.")
        
        // ç§»é™¤å¯èƒ½çš„BOMæ ‡è®°
        if cleaned.hasPrefix("\u{FEFF}") {
            cleaned = String(cleaned.dropFirst())
        }
        
        return cleaned
    }
    
    /// ä»æ–‡æœ¬ä¸­æå–åŸºæœ¬ä¿¡æ¯ï¼ˆå¤‡ç”¨æ–¹æ¡ˆ - å¢å¼ºç‰ˆï¼‰
    private func extractBasicInfoFromText(_ content: String) -> LabubuAIAnalysis {
        print("ğŸ”§ ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯...")
        
        let lowercaseContent = content.lowercased()
        
        // åˆ¤æ–­æ˜¯å¦ä¸ºLabubu
        let isLabubu = lowercaseContent.contains("labubu") || 
                      lowercaseContent.contains("æ˜¯") ||
                      lowercaseContent.contains("true")
        
        // æå–ç½®ä¿¡åº¦
        let confidence: Double
        if let confMatch = content.range(of: "\\d+\\.\\d+", options: .regularExpression) {
            confidence = Double(String(content[confMatch])) ?? (isLabubu ? 0.7 : 0.1)
        } else {
            confidence = isLabubu ? 0.7 : 0.1
        }
        
        // å°è¯•ä»æ–‡æœ¬ä¸­æå–å…³é”®ç‰¹å¾
        var extractedKeyFeatures: [String] = []
        
        // é¢œè‰²ç‰¹å¾
        let colorKeywords = ["è“è‰²", "æ£•è‰²", "ç™½è‰²", "ç°è‰²", "é»„è‰²", "é»‘è‰²", "ç²‰è‰²", "ç»¿è‰²", "çº¢è‰²", "ç´«è‰²", "æ©™è‰²", "ç±³è‰²"]
        for color in colorKeywords {
            if lowercaseContent.contains(color) {
                extractedKeyFeatures.append(color)
            }
        }
        
        // æè´¨ç‰¹å¾
        let materialKeywords = ["æ¯›ç»’", "æªèƒ¶", "å¡‘æ–™", "ç»’æ¯›", "plush", "vinyl"]
        for material in materialKeywords {
            if lowercaseContent.contains(material) {
                extractedKeyFeatures.append(material)
            }
        }
        
        // ç³»åˆ—ç‰¹å¾
        let seriesKeywords = ["time to chill", "æ”¾æ¾", "ä¼‘é—²", "fall in wild", "é‡å¤–", "æ˜¥å¤©", "monsters", "æ€ªç‰©", "checkmate", "å›½é™…è±¡æ£‹"]
        for series in seriesKeywords {
            if lowercaseContent.contains(series) {
                extractedKeyFeatures.append(series)
            }
        }
        
        // å½¢çŠ¶ç‰¹å¾
        let shapeKeywords = ["å…”è€³", "å¤§çœ¼", "åœ†å½¢", "èƒŒå¸¦è£¤", "å¤´å¥—"]
        for shape in shapeKeywords {
            if lowercaseContent.contains(shape) {
                extractedKeyFeatures.append(shape)
            }
        }
        
        print("ğŸ”§ å¤‡ç”¨æ–¹æ¡ˆç»“æœ: isLabubu=\(isLabubu), confidence=\(confidence)")
        print("ğŸ”§ æå–çš„å…³é”®ç‰¹å¾: \(extractedKeyFeatures)")
        
        return LabubuAIAnalysis(
            isLabubu: isLabubu,
            confidence: confidence,
            detailedDescription: content,
            visualFeatures: nil,
            keyFeatures: extractedKeyFeatures,
            seriesHints: extractedKeyFeatures.joined(separator: ", "),
            materialAnalysis: "",
            styleAnalysis: "",
            conditionAssessment: "",
            rarityHints: ""
        )
    }
    
    /// ä¸æ•°æ®åº“è¿›è¡ŒåŒ¹é…
    private func matchWithDatabase(_ aiAnalysis: LabubuAIAnalysis) async throws -> [LabubuDatabaseMatch] {
        print("ğŸ” å¼€å§‹ä¸æ•°æ®åº“è¿›è¡Œæ™ºèƒ½åŒ¹é…...")
        
        // å¦‚æœAIåˆ¤æ–­ä¸æ˜¯Labubuï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
        guard aiAnalysis.isLabubu else {
            print("âŒ AIåˆ¤æ–­ä¸æ˜¯Labubuï¼Œè·³è¿‡åŒ¹é…")
            return []
        }
        
        // è·å–æ‰€æœ‰æ•°æ®åº“ä¸­çš„æ¨¡å‹
        let allModelData = try await databaseService.fetchAllActiveModels()
        print("ğŸ“Š è·å–åˆ° \(allModelData.count) ä¸ªæ•°æ®åº“æ¨¡å‹è¿›è¡ŒåŒ¹é…")
        
        // ä½¿ç”¨AIæè¿°è¿›è¡Œæ™ºèƒ½ç›¸ä¼¼åº¦åŒ¹é…
        var matches: [LabubuDatabaseMatch] = []
        
        for (index, modelData) in allModelData.enumerated() {
            print("ğŸ” æ­£åœ¨åŒ¹é…æ¨¡å‹ \(index + 1)/\(allModelData.count): \(modelData.name)")
            
            // è§£ææ•°æ®åº“æ¨¡å‹çš„ç‰¹å¾æè¿°
            let modelFeatureText = extractFeatureText(from: modelData)
            print("ğŸ“ æ¨¡å‹ç‰¹å¾æ–‡æœ¬é•¿åº¦: \(modelFeatureText.count) å­—ç¬¦")
            
            // è®¡ç®—ç›¸ä¼¼åº¦
            let similarity = calculateAdvancedTextSimilarity(
                userDescription: aiAnalysis.detailedDescription,
                modelFeatureText: modelFeatureText,
                userKeyFeatures: aiAnalysis.keyFeatures
            )
            
            print("ğŸ“Š ç›¸ä¼¼åº¦å¾—åˆ†: \(String(format: "%.3f", similarity))")
            
            // æ·»åŠ æ‰€æœ‰åŒ¹é…ç»“æœï¼Œä¸è®¾é˜ˆå€¼é™åˆ¶
            let matchedFeatures = extractMatchedFeatures(aiAnalysis, modelFeatureText)
            
                matches.append(LabubuDatabaseMatch(
                model: modelData,
                    similarity: similarity,
                matchedFeatures: matchedFeatures
                ))
            
            print("âœ… æ·»åŠ åŒ¹é…ç»“æœ: \(modelData.name) (ç›¸ä¼¼åº¦: \(String(format: "%.3f", similarity)))")
        }
        
        // æŒ‰ç›¸ä¼¼åº¦æ’åº
        matches.sort { $0.similarity > $1.similarity }
        print("ğŸ† åŒ¹é…å®Œæˆï¼Œæ‰¾åˆ° \(matches.count) ä¸ªå€™é€‰ç»“æœ")
        
        // æ‰“å°å‰3ä¸ªæœ€ä½³åŒ¹é…
        for (index, match) in matches.prefix(3).enumerated() {
            print("ğŸ¥‡ ç¬¬\(index + 1)å: \(match.model.name) (ç›¸ä¼¼åº¦: \(String(format: "%.3f", match.similarity)))")
        }
        
        // è¿”å›å‰5ä¸ªæœ€ä½³åŒ¹é…
        return Array(matches.prefix(5))
    }
    
    /// ä»LabubuModelDataä¸­æå–ç‰¹å¾æ–‡æœ¬
    private func extractFeatureText(from modelData: LabubuModelData) -> String {
        var featureTexts: [String] = []
        
        // æ·»åŠ åŸºæœ¬ä¿¡æ¯
        featureTexts.append(modelData.name)
        if let nameEn = modelData.nameEn, nameEn != modelData.name {
            featureTexts.append(nameEn)
        }
        
        // è§£æfeature_description JSON
        if let featureDescription = modelData.featureDescription,
           let data = featureDescription.data(using: .utf8) {
            do {
                if let json = try JSONSerialization.jsonObject(with: data) as? [String: Any] {
                    // æå–è¯¦ç»†æè¿°
                    if let detailedDesc = json["detailedDescription"] as? String {
                        featureTexts.append(detailedDesc)
                    }
                    
                    // æå–å…³é”®ç‰¹å¾
                    if let keyFeatures = json["keyFeatures"] as? [String] {
                        featureTexts.append(contentsOf: keyFeatures)
                    }
                    
                    // æå–æè´¨åˆ†æ
                    if let materialAnalysis = json["materialAnalysis"] as? String {
                        featureTexts.append(materialAnalysis)
                    }
                    
                    // æå–é£æ ¼åˆ†æ
                    if let styleAnalysis = json["styleAnalysis"] as? String {
                        featureTexts.append(styleAnalysis)
                    }
                    
                    // æå–è§†è§‰ç‰¹å¾
                    if let visualFeatures = json["visualFeatures"] as? [String: Any] {
                        for (_, value) in visualFeatures {
                            if let stringValue = value as? String {
                                featureTexts.append(stringValue)
                            } else if let arrayValue = value as? [String] {
                                featureTexts.append(contentsOf: arrayValue)
                            }
                        }
                    }
                }
            } catch {
                print("âš ï¸ è§£æfeature_description JSONå¤±è´¥: \(error)")
            }
        }
        
        // æ·»åŠ ç¨€æœ‰åº¦ä¿¡æ¯
        featureTexts.append(modelData.rarityLevel)
        
        // âœ¨ æ–°å¢ï¼šæ ¹æ®æ¨¡å‹åç§°æ˜ å°„ç³»åˆ—åŒä¹‰è¯ï¼Œå¢å¼ºç³»åˆ—åŒ¹é…
        let seriesSynonymMap: [String: [String]] = [
            "time to chill": ["time to chill", "time chill", "chill", "æ”¾æ¾", "ä¼‘é—²", "æ—¶é—´", "time", "to"],
            "fall in wild": ["fall in wild", "æ˜¥å¤©åœ¨é‡", "fall wild", "wild", "é‡å¤–", "fall", "spring", "æ˜¥å¤©"],
            "walk by fortune": ["walk by fortune", "fortune", "è´¢å¯Œ", "walk", "by"],
            "best of luck": ["best of luck", "best luck", "å¥½è¿", "luck", "best"],
            "checkmate": ["checkmate", "chess", "æ£‹", "å›½é™…è±¡æ£‹", "check", "mate"],
            "flip with me": ["flip with me", "flip me", "ç¿»è½¬", "flip", "with"],
            "dress be latte": ["dress be latte", "latte", "æ‹¿é“", "dress", "be"],
            "jump for joy": ["jump for joy", "jump joy", "è·³è·ƒ", "jump", "joy"],
            "monsters": ["monsters", "the monsters", "monster", "æ€ªç‰©"]
        ]
        
        let lowerName = modelData.name.lowercased()
        for (key, synonyms) in seriesSynonymMap {
            if lowerName.contains(key) {
                featureTexts.append(contentsOf: synonyms)
                print("ğŸ·ï¸ [ç³»åˆ—å¢å¼º] ä¸ºæ¨¡å‹ '\(modelData.name)' æ·»åŠ ç³»åˆ—åŒä¹‰è¯: \(synonyms)")
            }
        }
        
        return featureTexts.joined(separator: " ")
    }
    
    /// è®¡ç®—é«˜çº§æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    private func calculateAdvancedTextSimilarity(
        userDescription: String,
        modelFeatureText: String,
        userKeyFeatures: [String]
    ) -> Double {
        print("ğŸ” å¼€å§‹è®¡ç®—ç›¸ä¼¼åº¦...")
        print("ğŸ‘¤ ç”¨æˆ·æè¿°: \(userDescription.prefix(100))...")
        print("ğŸ·ï¸ ç”¨æˆ·å…³é”®ç‰¹å¾: \(userKeyFeatures)")
        print("ğŸ—„ï¸ æ¨¡å‹ç‰¹å¾æ–‡æœ¬: \(modelFeatureText.prefix(100))...")
        
        // 1. æ™ºèƒ½è¯æ±‡ç›¸ä¼¼åº¦ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        let basicSimilarity = calculateSmartWordSimilarity(userDescription: userDescription, modelText: modelFeatureText)
        print("ğŸ“Š æ™ºèƒ½è¯æ±‡ç›¸ä¼¼åº¦: \(String(format: "%.3f", basicSimilarity))")
        
        // 2. å…³é”®ç‰¹å¾åŒ¹é…åº¦ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        var keyFeatureScore = 0.0
        var matchedFeatures: [String] = []
        
        for feature in userKeyFeatures {
            let featureScore = calculateFeatureMatch(feature: feature, modelText: modelFeatureText)
            keyFeatureScore += featureScore
            if featureScore > 0.3 {
                matchedFeatures.append(feature)
            }
            print("ğŸ” ç‰¹å¾åŒ¹é…: '\(feature)' -> \(String(format: "%.3f", featureScore))")
        }
        
        let keyFeatureSimilarity = userKeyFeatures.isEmpty ? 0.0 : keyFeatureScore / Double(userKeyFeatures.count)
        print("ğŸ“Š å…³é”®ç‰¹å¾ç›¸ä¼¼åº¦: \(String(format: "%.3f", keyFeatureSimilarity)) (åŒ¹é…ç‰¹å¾: \(matchedFeatures))")
        
        // 3. ç³»åˆ—åç§°åŒ¹é…åº¦ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        let seriesScore = calculateSeriesMatch(userDescription: userDescription, modelText: modelFeatureText)
        print("ğŸ“Š ç³»åˆ—åŒ¹é…åº¦: \(String(format: "%.3f", seriesScore))")
        
        // 4. é¢œè‰²åŒ¹é…åº¦ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        let colorScore = calculateColorMatch(userDescription: userDescription, modelText: modelFeatureText)
        print("ğŸ“Š é¢œè‰²åŒ¹é…åº¦: \(String(format: "%.3f", colorScore))")
        
        // 5. æ¨¡å‹åç§°ç›´æ¥åŒ¹é…åº¦ï¼ˆæ–°å¢ï¼‰
        let nameScore = calculateNameMatch(userDescription: userDescription, modelText: modelFeatureText)
        print("ğŸ“Š åç§°åŒ¹é…åº¦: \(String(format: "%.3f", nameScore))")
        
        // ç»¼åˆç›¸ä¼¼åº¦è®¡ç®— (ä¼˜åŒ–æƒé‡åˆ†é…)
        let finalSimilarity = basicSimilarity * 0.25 + 
                             keyFeatureSimilarity * 0.30 + 
                             seriesScore * 0.15 + 
                             colorScore * 0.10 + 
                             nameScore * 0.20
        
        print("ğŸ¯ æœ€ç»ˆç›¸ä¼¼åº¦: \(String(format: "%.3f", finalSimilarity))")
        print("ğŸ“ˆ æƒé‡åˆ†å¸ƒ: è¯æ±‡(\(String(format: "%.3f", basicSimilarity * 0.25))) + ç‰¹å¾(\(String(format: "%.3f", keyFeatureSimilarity * 0.30))) + ç³»åˆ—(\(String(format: "%.3f", seriesScore * 0.15))) + é¢œè‰²(\(String(format: "%.3f", colorScore * 0.10))) + åç§°(\(String(format: "%.3f", nameScore * 0.20)))")
        
        return finalSimilarity
    }
    
    /// æ™ºèƒ½è¯æ±‡ç›¸ä¼¼åº¦è®¡ç®—
    private func calculateSmartWordSimilarity(userDescription: String, modelText: String) -> Double {
        let separators = CharacterSet.whitespacesAndNewlines.union(.punctuationCharacters)
        
        // å¤„ç†ç”¨æˆ·æè¿°
        let userWords = Set(userDescription.lowercased()
            .components(separatedBy: separators)
            .filter { $0.count > 1 }) // é™ä½æœ€å°é•¿åº¦è¦æ±‚
        
        // å¤„ç†æ¨¡å‹ç‰¹å¾æ–‡æœ¬
        let modelWords = Set(modelText.lowercased()
            .components(separatedBy: separators)
            .filter { $0.count > 1 })
        
        // ç›´æ¥åŒ¹é…
        let directIntersection = userWords.intersection(modelWords)
        let directUnion = userWords.union(modelWords)
        let directSimilarity = directUnion.isEmpty ? 0.0 : Double(directIntersection.count) / Double(directUnion.count)
        
        // è¯­ä¹‰åŒ¹é…
        var semanticMatches = 0
        let semanticMappings: [String: [String]] = [
            // è‹±æ–‡-ä¸­æ–‡æ˜ å°„
            "time": ["æ—¶é—´", "time", "chill"],
            "chill": ["æ”¾æ¾", "ä¼‘é—²", "chill", "time"],
            "to": ["åˆ°", "å»", "to"],
            "labubu": ["labubu", "æ‹‰å¸ƒå¸ƒ"],
            "monsters": ["æ€ªç‰©", "monsters", "monster"],
            "fall": ["ç§‹å¤©", "fall", "autumn"],
            "wild": ["é‡å¤–", "wild", "nature"],
            "spring": ["æ˜¥å¤©", "spring", "æ˜¥"],
            "vinyl": ["æªèƒ¶", "vinyl", "å¡‘æ–™"],
            "plush": ["æ¯›ç»’", "plush", "ç»’æ¯›"],
            "doll": ["å¨ƒå¨ƒ", "doll", "ç©å¶"],
            // é¢œè‰²æ˜ å°„
            "blue": ["è“è‰²", "blue", "æ·±è“", "é›è“"],
            "brown": ["æ£•è‰²", "brown", "å’–å•¡è‰²"],
            "white": ["ç™½è‰²", "white", "ç±³ç™½"],
            "gray": ["ç°è‰²", "gray", "grey"],
            "yellow": ["é»„è‰²", "yellow"],
            // æè´¨æ˜ å°„
            "ç»’æ¯›": ["æ¯›ç»’", "plush", "ç»’å¸ƒ", "ç»’æ¯›"],
            "èƒŒå¸¦è£¤": ["èƒŒå¸¦è£¤", "overalls", "suspenders"],
            "å…”è€³": ["å…”è€³", "rabbit ears", "ears"],
            "å¤´å¥—": ["å¤´å¥—", "hood", "hat"]
        ]
        
        for userWord in userWords {
            for (key, synonyms) in semanticMappings {
                if userWord.contains(key) || key.contains(userWord) {
                    for synonym in synonyms {
                        if modelWords.contains(where: { $0.contains(synonym) }) {
                            semanticMatches += 1
                            break
                        }
                    }
                }
            }
        }
        
        let semanticSimilarity = userWords.isEmpty ? 0.0 : Double(semanticMatches) / Double(userWords.count)
        
        // ç»„åˆç›¸ä¼¼åº¦
        let combinedSimilarity = max(directSimilarity, semanticSimilarity * 0.8)
        
        print("ğŸ“Š è¯æ±‡åŒ¹é…è¯¦æƒ…: ç›´æ¥(\(String(format: "%.3f", directSimilarity))) + è¯­ä¹‰(\(String(format: "%.3f", semanticSimilarity))) = æœ€ç»ˆ(\(String(format: "%.3f", combinedSimilarity)))")
        print("ğŸ“Š åŒ¹é…è¯æ•°: ç›´æ¥(\(directIntersection.count)/\(directUnion.count)) + è¯­ä¹‰(\(semanticMatches)/\(userWords.count))")
        
        return combinedSimilarity
    }
    
    /// æ¨¡å‹åç§°åŒ¹é…åº¦
    private func calculateNameMatch(userDescription: String, modelText: String) -> Double {
        let userLower = userDescription.lowercased()
        let modelLower = modelText.lowercased()
        
        // æå–æ¨¡å‹åç§°å…³é”®è¯
        let nameKeywords = [
            "time to chill", "best of luck", "checkmate", "flip with me",
            "dress be latte", "jump for joy", "walk by fortune", "fall in wild",
            "æ˜¥å¤©åœ¨é‡", "æ—¶é—´æ”¾æ¾", "å¥½è¿è¿è¿"
        ]
        
        var maxScore = 0.0
        
        for keyword in nameKeywords {
            let keywordLower = keyword.lowercased()
            
            // å®Œå…¨åŒ¹é…
            if userLower.contains(keywordLower) && modelLower.contains(keywordLower) {
                maxScore = max(maxScore, 1.0)
                continue
            }
            
            // éƒ¨åˆ†åŒ¹é…
            let keywordWords = keywordLower.components(separatedBy: " ")
            var partialMatches = 0
            
            for word in keywordWords {
                if userLower.contains(word) && modelLower.contains(word) {
                    partialMatches += 1
                }
            }
            
            if keywordWords.count > 0 {
                let partialScore = Double(partialMatches) / Double(keywordWords.count)
                maxScore = max(maxScore, partialScore * 0.8)
            }
        }
        
        return maxScore
    }
    
    /// è®¡ç®—å•ä¸ªç‰¹å¾çš„åŒ¹é…åº¦ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    private func calculateFeatureMatch(feature: String, modelText: String) -> Double {
        let featureLower = feature.lowercased()
        let modelLower = modelText.lowercased()
        
        // ç›´æ¥åŒ¹é…
        if modelLower.contains(featureLower) {
            return 1.0
        }
        
        // æ‰©å±•è¯­ä¹‰åŒ¹é…æ˜ å°„
        let semanticMappings: [String: [String]] = [
            // å¤´éƒ¨ç‰¹å¾
            "æ£•è‰²æ¯›èŒ¸èŒ¸å…”å­å¤´å¥—": ["æ£•è‰²", "å…”å¸½", "å…”å­å¤´å¥—", "å¤´å¥—", "æ¯›ç»’", "ç»’æ¯›", "brown", "rabbit", "hood"],
            "ç±³è‰²é•¿ç›´ç«‹å…”è€³æœµ": ["ç±³è‰²", "å…”è€³", "è€³æœµ", "ç›´ç«‹", "é•¿è€³", "beige", "ears", "rabbit ears"],
            "æµ…æ£•è‰²è„¸éƒ¨": ["æµ…æ£•è‰²", "è„¸éƒ¨", "é¢éƒ¨", "æ·¡æ£•", "light brown", "face"],
            "å¤§çœ¼ç›": ["å¤§çœ¼ç›", "çœ¼ç›", "ç³å­”", "é»‘çœ¼", "eyes", "big eyes"],
            "é”¯é½¿çŠ¶ç‰™é½¿": ["é”¯é½¿", "ç‰™é½¿", "é½¿çŠ¶", "teeth", "zigzag"],
            
            // æœè£…ç‰¹å¾
            "ç°è‰²é•¿è¢–ä¸Šè¡£": ["ç°è‰²", "é•¿è¢–", "ä¸Šè¡£", "è¡¬è¡£", "gray", "grey", "shirt", "top"],
            "æ·±è“è‰²ç¯èŠ¯ç»’èƒŒå¸¦è£¤": ["æ·±è“è‰²", "è“è‰²", "èƒŒå¸¦è£¤", "ç¯èŠ¯ç»’", "èƒŒå¸¦", "blue", "overalls", "suspenders", "corduroy"],
            "èƒŒå¸¦è£¤èƒ¸å‰é»„è‰²å£è¢‹": ["é»„è‰²", "å£è¢‹", "èƒ¸å‰", "å‰è¢‹", "yellow", "pocket", "chest"],
            "èƒŒå¸¦è£¤è…¿éƒ¨ç ´æ´å›¾æ¡ˆ": ["ç ´æ´", "å›¾æ¡ˆ", "è…¿éƒ¨", "æ´", "hole", "pattern", "leg"],
            
            // é€šç”¨ç‰¹å¾
            "æ¯›ç»’": ["æ¯›ç»’", "ç»’æ¯›", "é•¿ç»’", "plush", "ç»’å¸ƒ", "fuzzy"],
            "èƒŒå¿ƒ": ["èƒŒå¿ƒ", "è¡¬è¡£", "ä¸Šè¡£", "vest", "shirt", "top"],
            "èŠ±æœµ": ["èŠ±æœµ", "é›èŠ", "èŠ±", "flower", "daisy", "floral"],
            "è“è‰²": ["è“è‰²", "æ·±è“", "é›è“", "blue", "navy"],
            "ç™½è‰²": ["ç™½è‰²", "ç±³ç™½", "æ·¡ç™½", "white", "cream"],
            "æ£•è‰²": ["æ£•è‰²", "å’–å•¡è‰²", "brown", "coffee"],
            "å¡å…¶": ["å¡å…¶", "å¡å…¶è‰²", "khaki", "tan"],
            "çœ¼ç›": ["çœ¼ç›", "ç³å­”", "å¤§çœ¼", "eye", "eyes"],
            "è€³æœµ": ["è€³æœµ", "å…”è€³", "ear", "ears"],
            
            // æè´¨ç‰¹å¾
            "ç»’æ¯›": ["ç»’æ¯›", "æ¯›ç»’", "plush", "fuzzy", "soft"],
            "æªèƒ¶": ["æªèƒ¶", "vinyl", "plastic"],
            "å¡‘æ–™": ["å¡‘æ–™", "plastic", "vinyl"]
        ]
        
        // æ£€æŸ¥è¯­ä¹‰åŒ¹é…
        var maxSemanticScore = 0.0
        for (key, synonyms) in semanticMappings {
            if featureLower.contains(key) || key.contains(featureLower) {
                for synonym in synonyms {
                    if modelLower.contains(synonym.lowercased()) {
                        maxSemanticScore = max(maxSemanticScore, 0.8)
                    }
                }
            }
        }
        
        // éƒ¨åˆ†åŒ¹é…ï¼ˆé™ä½è¯é•¿è¦æ±‚ï¼‰
        let featureWords = featureLower.components(separatedBy: CharacterSet.whitespacesAndNewlines.union(.punctuationCharacters))
            .filter { $0.count > 1 } // é™ä½æœ€å°é•¿åº¦è¦æ±‚
        
        var partialMatches = 0
        for word in featureWords {
            if modelLower.contains(word) {
                partialMatches += 1
            }
        }
        
        let partialScore = featureWords.isEmpty ? 0.0 : Double(partialMatches) / Double(featureWords.count) * 0.6
        
        // è¿”å›æœ€é«˜åˆ†æ•°
        return max(maxSemanticScore, partialScore)
    }
    
    /// è®¡ç®—ç³»åˆ—åç§°åŒ¹é…åº¦ï¼ˆä¼˜åŒ–ç‰ˆ - æ›´å®½æ¾çš„åŒ¹é…ç­–ç•¥ï¼‰
    private func calculateSeriesMatch(userDescription: String, modelText: String) -> Double {
        let userLower = userDescription.lowercased()
        let modelLower = modelText.lowercased()
        
        // ç³»åˆ—å…³é”®è¯æ˜ å°„ï¼ˆåŒ…å«åŒä¹‰è¯å’Œå˜ä½“ï¼‰
        let seriesKeywords: [String: [String]] = [
            "time_to_chill": ["time to chill", "time chill", "chill", "æ”¾æ¾", "ä¼‘é—²"],
            "fall_in_wild": ["fall in wild", "æ˜¥å¤©åœ¨é‡", "fall wild", "é‡å¤–", "wild"],
            "monsters": ["monsters", "the monsters", "monster", "æ€ªç‰©"],
            "best_of_luck": ["best of luck", "best luck", "å¥½è¿", "luck"],
            "checkmate": ["checkmate", "chess", "å›½é™…è±¡æ£‹"],
            "flip_with_me": ["flip with me", "flip me", "ç¿»è½¬"],
            "dress_be_latte": ["dress be latte", "latte", "æ‹¿é“"],
            "jump_for_joy": ["jump for joy", "jump joy", "è·³è·ƒ"],
            "walk_by_fortune": ["walk by fortune", "fortune", "è´¢å¯Œ"]
        ]
        
        var maxScore = 0.0
        
        for (_, keywords) in seriesKeywords {
            var seriesScore = 0.0
            
            for keyword in keywords {
                let keywordLower = keyword.lowercased()
                
                // ç­–ç•¥1: å®Œå…¨åŒ¹é…ï¼ˆç”¨æˆ·å’Œæ¨¡å‹éƒ½åŒ…å«ï¼‰
                if userLower.contains(keywordLower) && modelLower.contains(keywordLower) {
                    seriesScore = max(seriesScore, 1.0)
                    continue
                }
                
                // ç­–ç•¥2: å•å‘åŒ¹é…ï¼ˆç”¨æˆ·åŒ…å«å…³é”®è¯ï¼Œæ¨¡å‹åŒ…å«ç³»åˆ—ä¸­ä»»ä¸€åŒä¹‰è¯ï¼‰
                if userLower.contains(keywordLower) {
                    for otherKeyword in keywords {
                        if modelLower.contains(otherKeyword.lowercased()) {
                            seriesScore = max(seriesScore, 0.8)
                            break
                        }
                    }
                }
                
                // ç­–ç•¥3: åå‘åŒ¹é…ï¼ˆæ¨¡å‹åŒ…å«å…³é”®è¯ï¼Œç”¨æˆ·åŒ…å«ç³»åˆ—ä¸­ä»»ä¸€åŒä¹‰è¯ï¼‰
                if modelLower.contains(keywordLower) {
                    for otherKeyword in keywords {
                        if userLower.contains(otherKeyword.lowercased()) {
                            seriesScore = max(seriesScore, 0.8)
                            break
                        }
                    }
                }
                
                // ç­–ç•¥4: éƒ¨åˆ†åŒ¹é…ï¼ˆå¤šè¯å…³é”®è¯çš„éƒ¨åˆ†åŒ¹é…ï¼‰
                let keywordWords = keywordLower.components(separatedBy: " ")
                if keywordWords.count > 1 {
                    var userMatches = 0
                    var modelMatches = 0
                    
                    for word in keywordWords {
                        if word.count > 2 {
                            if userLower.contains(word) { userMatches += 1 }
                            if modelLower.contains(word) { modelMatches += 1 }
                        }
                    }
                    
                    // å¦‚æœç”¨æˆ·æˆ–æ¨¡å‹æœ‰éƒ¨åˆ†åŒ¹é…ï¼Œç»™äºˆä¸€å®šåˆ†æ•°
                    if userMatches > 0 && modelMatches > 0 {
                        let partialScore = Double(min(userMatches, modelMatches)) / Double(keywordWords.count) * 0.6
                        seriesScore = max(seriesScore, partialScore)
                    } else if userMatches > 0 || modelMatches > 0 {
                        let singleSideScore = Double(max(userMatches, modelMatches)) / Double(keywordWords.count) * 0.4
                        seriesScore = max(seriesScore, singleSideScore)
                    }
                }
            }
            
            maxScore = max(maxScore, seriesScore)
        }
        
        return maxScore
    }
    
    /// è®¡ç®—é¢œè‰²åŒ¹é…åº¦ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
    private func calculateColorMatch(userDescription: String, modelText: String) -> Double {
        let userLower = userDescription.lowercased()
        let modelLower = modelText.lowercased()
        
        // é¢œè‰²å…³é”®è¯æ˜ å°„ï¼ˆåŒ…å«åŒä¹‰è¯å’Œå˜ä½“ï¼‰
        let colorKeywords: [String: [String]] = [
            "è“è‰²": ["è“è‰²", "æ·±è“", "é›è“", "è“", "blue", "navy", "æ·±è“è‰²"],
            "æ£•è‰²": ["æ£•è‰²", "å’–å•¡è‰²", "æµ…æ£•è‰²", "æ·±æ£•è‰²", "æ£•", "brown", "coffee", "tan"],
            "ç™½è‰²": ["ç™½è‰²", "ç±³ç™½", "æ·¡ç™½", "å¥¶ç™½", "ç™½", "white", "cream", "ivory"],
            "ç°è‰²": ["ç°è‰²", "æ·±ç°", "æµ…ç°", "ç°", "gray", "grey"],
            "é»„è‰²": ["é»„è‰²", "é‡‘é»„", "æ·¡é»„", "é»„", "yellow", "gold"],
            "é»‘è‰²": ["é»‘è‰²", "æ·±é»‘", "é»‘", "black"],
            "ç²‰è‰²": ["ç²‰è‰²", "æ·¡ç²‰", "ç²‰çº¢", "ç²‰", "pink", "rose"],
            "ç»¿è‰²": ["ç»¿è‰²", "æ·±ç»¿", "æµ…ç»¿", "ç»¿", "green"],
            "çº¢è‰²": ["çº¢è‰²", "æ·±çº¢", "æµ…çº¢", "çº¢", "red"],
            "ç´«è‰²": ["ç´«è‰²", "æ·±ç´«", "æµ…ç´«", "ç´«", "purple"],
            "æ©™è‰²": ["æ©™è‰²", "æ©˜è‰²", "æ©™", "orange"],
            "ç±³è‰²": ["ç±³è‰²", "ç±³ç™½", "beige", "cream"]
        ]
        
        var totalMatches = 0
        var totalColors = 0
        
        for (_, colorVariants) in colorKeywords {
            var colorMatched = false
            
            for variant in colorVariants {
                if userLower.contains(variant) {
                    totalColors += 1
                    
                    // æ£€æŸ¥æ¨¡å‹æ–‡æœ¬ä¸­æ˜¯å¦æœ‰ç›¸åŒé¢œè‰²æ—çš„ä»»ä½•å˜ä½“
                    for modelVariant in colorVariants {
                        if modelLower.contains(modelVariant) {
                            totalMatches += 1
                            colorMatched = true
                            break
                        }
                    }
                    
                    if colorMatched {
                        break
                    }
                }
            }
        }
        
        return totalColors == 0 ? 0.0 : Double(totalMatches) / Double(totalColors)
    }
    
    /// æå–åŒ¹é…çš„ç‰¹å¾
    private func extractMatchedFeatures(_ aiAnalysis: LabubuAIAnalysis, _ modelFeatureText: String) -> [String] {
        var matchedFeatures: [String] = []
        
        // æ¯”è¾ƒå…³é”®ç‰¹å¾
        for feature in aiAnalysis.keyFeatures {
            if modelFeatureText.lowercased().contains(feature.lowercased()) {
                matchedFeatures.append(feature)
            }
        }
        
        return matchedFeatures
    }
    

    
    /// è½¬æ¢ç¨€æœ‰åº¦å­—ç¬¦ä¸²ä¸ºRarityLevel
    private func convertStringToRarity(_ rarity: String) -> RarityLevel {
        switch rarity.lowercased() {
        case "common": return .common
        case "uncommon": return .uncommon
        case "rare": return .rare
        case "ultra_rare": return .epic
        case "secret": return .secret
        default: return .common
        }
    }
    
    /// åˆ›å»ºé»˜è®¤è§†è§‰ç‰¹å¾
    private func createDefaultVisualFeatures() -> VisualFeatures {
        return VisualFeatures(
            primaryColors: [],
            colorDistribution: [:],
            shapeDescriptor: ShapeDescriptor(
                aspectRatio: 0.8,
                roundness: 0.85,
                symmetry: 0.9,
                complexity: 0.4,
                keyPoints: []
            ),
            contourPoints: nil,
            textureFeatures: LabubuTextureFeatures(
                smoothness: 0.7,
                roughness: 0.3,
                patterns: [],
                materialType: .plush
            ),
            specialMarks: [],
            featureVector: []
        )
    }
    
    /// è·å–APIå¯†é’¥
    private func getAPIKey() -> String? {
        // ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–
        if let envKey = ProcessInfo.processInfo.environment["TUZI_API_KEY"], 
           !envKey.isEmpty,
           envKey != "your_api_key_here" {
            return envKey
        }
        
        // å°è¯•ä».envæ–‡ä»¶è¯»å–
        if let envFileKey = loadValueFromEnvFile(key: "TUZI_API_KEY"),
           !envFileKey.isEmpty,
           envFileKey != "your_api_key_here" {
            return envFileKey
        }
        
        // å‘åå…¼å®¹ï¼šä»ç¯å¢ƒå˜é‡è¯»å–OPENAI_API_KEY
        if let envKey = ProcessInfo.processInfo.environment["OPENAI_API_KEY"],
           !envKey.isEmpty,
           envKey != "your_api_key_here" {
            return envKey
        }
        
        // å‘åå…¼å®¹ï¼šä».envæ–‡ä»¶è¯»å–OPENAI_API_KEY
        if let envFileKey = loadValueFromEnvFile(key: "OPENAI_API_KEY"),
           !envFileKey.isEmpty,
           envFileKey != "your_api_key_here" {
            return envFileKey
        }
        
        // å¤‡é€‰ä»UserDefaultsè·å–ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        return UserDefaults.standard.string(forKey: "tuzi_api_key")
    }
    
    /// è·å–APIåŸºç¡€URL
    private func getAPIBaseURL() -> String? {
        // ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è·å–
        if let envURL = ProcessInfo.processInfo.environment["TUZI_API_BASE"],
           !envURL.isEmpty {
            return envURL
        }
        
        // å°è¯•ä».envæ–‡ä»¶è¯»å–
        if let envFileURL = loadValueFromEnvFile(key: "TUZI_API_BASE"),
           !envFileURL.isEmpty {
            return envFileURL
        }
        
        // å¤‡é€‰ä»UserDefaultsè·å–ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        return UserDefaults.standard.string(forKey: "tuzi_api_base") ?? "https://api.tu-zi.com/v1"
    }
    
    /// ä».envæ–‡ä»¶åŠ è½½æŒ‡å®šé”®çš„å€¼
    private func loadValueFromEnvFile(key: String) -> String? {
        // è·å–åº”ç”¨Bundleè·¯å¾„
        guard let bundlePath = Bundle.main.resourcePath else { return nil }
        let envPath = bundlePath + "/.env"
        
        // å¦‚æœBundleä¸­æ²¡æœ‰.envæ–‡ä»¶ï¼Œå°è¯•é¡¹ç›®æ ¹ç›®å½•
        let projectEnvPath = bundlePath + "/../../.env"
        
        for path in [envPath, projectEnvPath] {
            if FileManager.default.fileExists(atPath: path) {
                do {
                    let content = try String(contentsOfFile: path, encoding: .utf8)
                    let lines = content.components(separatedBy: .newlines)
                    
                    for line in lines {
                        let trimmedLine = line.trimmingCharacters(in: .whitespacesAndNewlines)
                        if trimmedLine.hasPrefix("\(key)=") {
                            let value = String(trimmedLine.dropFirst("\(key)=".count))
                                .trimmingCharacters(in: .whitespacesAndNewlines)
                            if !value.isEmpty && value != "your_api_key_here" {
                                print("ğŸ“ LabubuAIä» \(path) è¯»å–åˆ°\(key)")
                                return value
                            }
                        }
                    }
                } catch {
                    print("âŒ LabubuAIè¯»å–.envæ–‡ä»¶å¤±è´¥: \(error)")
                }
            }
        }
        
        return nil
    }
}

// MARK: - æ•°æ®æ¨¡å‹

/// Labubu AIåˆ†æç»“æœ
struct LabubuAIAnalysis: Codable {
    let isLabubu: Bool
    let confidence: Double
    let detailedDescription: String
    let visualFeatures: LabubuVisualFeatures?
    let keyFeatures: [String]
    let seriesHints: String
    let materialAnalysis: String
    let styleAnalysis: String
    let conditionAssessment: String
    let rarityHints: String
}

/// è§†è§‰ç‰¹å¾
struct LabubuVisualFeatures: Codable {
    let dominantColors: [String]
    let bodyShape: String
    let headShape: String
    let earType: String
    let surfaceTexture: String
    let patternType: String
    let estimatedSize: String
}

/// æ•°æ®åº“åŒ¹é…ç»“æœ
struct LabubuDatabaseMatch: Codable {
    let model: LabubuModelData
    let similarity: Double
    let matchedFeatures: [String]
}

/// AIè¯†åˆ«ç»“æœ
struct LabubuAIRecognitionResult: Codable {
    let originalImageData: Data  // å­˜å‚¨å›¾ç‰‡æ•°æ®è€Œä¸æ˜¯UIImage
    let aiAnalysis: LabubuAIAnalysis
    let matchResults: [LabubuDatabaseMatch]
    let processingTime: TimeInterval
    let timestamp: Date
    
    /// åŸå§‹å›¾ç‰‡ï¼ˆä»æ•°æ®æ¢å¤ï¼‰
    var originalImage: UIImage? {
        return UIImage(data: originalImageData)
    }
    
    /// æœ€ä½³åŒ¹é…
    var bestMatch: LabubuModelData? {
        return matchResults.first?.model
    }
    
    /// æ˜¯å¦æˆåŠŸè¯†åˆ«
    var isSuccessful: Bool {
        return aiAnalysis.isLabubu && !matchResults.isEmpty
    }
    
    /// è¯†åˆ«ç½®ä¿¡åº¦
    var confidence: Double {
        if let bestMatch = matchResults.first {
            return aiAnalysis.confidence * bestMatch.similarity
        }
        return aiAnalysis.confidence
    }
    
    /// ä»UIImageåˆ›å»ºç»“æœçš„ä¾¿åˆ©åˆå§‹åŒ–å™¨
    init(originalImage: UIImage, aiAnalysis: LabubuAIAnalysis, matchResults: [LabubuDatabaseMatch], processingTime: TimeInterval, timestamp: Date) {
        self.originalImageData = originalImage.jpegData(compressionQuality: 0.8) ?? Data()
        self.aiAnalysis = aiAnalysis
        self.matchResults = matchResults
        self.processingTime = processingTime
        self.timestamp = timestamp
    }
}

// MARK: - é”™è¯¯ç±»å‹

enum LabubuAIError: LocalizedError {
    case imageProcessingFailed
    case apiConfigurationMissing
    case networkError(String)
    case invalidResponse
    case jsonParsingFailed
    case noMatchFound
    case apiTimeout
    case apiQuotaExceeded
    case apiRateLimited
    
    var errorDescription: String? {
        switch self {
        case .imageProcessingFailed:
            return "å›¾åƒå¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æ ¼å¼å’Œå¤§å°"
        case .apiConfigurationMissing:
            return "AIè¯†åˆ«æœåŠ¡é…ç½®ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®"
        case .networkError(let message):
            return "ç½‘ç»œè¿æ¥å¤±è´¥: \(message)"
        case .invalidResponse:
            return "AIæœåŠ¡å“åº”å¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•"
        case .jsonParsingFailed:
            return "AIåˆ†æç»“æœè§£æå¤±è´¥ï¼Œä½†å·²å°è¯•å¤‡ç”¨æ–¹æ¡ˆ"
        case .noMatchFound:
            return "æœªæ‰¾åˆ°åŒ¹é…çš„Labubuæ¨¡å‹ï¼Œå¯èƒ½æ˜¯æ–°æ¬¾æˆ–éLabubuç©å…·"
        case .apiTimeout:
            return "AIåˆ†æè¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•"
        case .apiQuotaExceeded:
            return "AIæœåŠ¡ä½¿ç”¨é‡å·²è¾¾ä¸Šé™ï¼Œè¯·ç¨åé‡è¯•"
        case .apiRateLimited:
            return "è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•"
        }
    }
    
    var recoverySuggestion: String? {
        switch self {
        case .imageProcessingFailed:
            return "è¯·å°è¯•ä½¿ç”¨æ¸…æ™°åº¦æ›´é«˜çš„å›¾ç‰‡ï¼Œç¡®ä¿å›¾ç‰‡å¤§å°åœ¨åˆç†èŒƒå›´å†…"
        case .apiConfigurationMissing:
            return "è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–è”ç³»æŠ€æœ¯æ”¯æŒ"
        case .networkError:
            return "è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œç¡®ä¿ç½‘ç»œç¨³å®šåé‡è¯•"
        case .invalidResponse, .jsonParsingFailed:
            return "è¿™å¯èƒ½æ˜¯ä¸´æ—¶é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•"
        case .noMatchFound:
            return "æ‚¨å¯ä»¥å°è¯•ä»ä¸åŒè§’åº¦æ‹æ‘„ï¼Œæˆ–æ‰‹åŠ¨æ·»åŠ åˆ°æ”¶è—"
        case .apiTimeout:
            return "è¯·ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šï¼Œæˆ–ç¨åé‡è¯•"
        case .apiQuotaExceeded, .apiRateLimited:
            return "è¯·ç¨ç­‰ç‰‡åˆ»åå†æ¬¡å°è¯•è¯†åˆ«"
        }
    }
} 